{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn import Embedding, Linear, Bilinear, BatchNorm1d, ReLU, Dropout, MarginRankingLoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosNegData:\n",
    "\n",
    "    def __init__(self, pos_data, neg_data, weight):\n",
    "        self.pos = pos_data\n",
    "        self.neg = neg_data\n",
    "        self.weight = weight\n",
    "\n",
    "\n",
    "class Data:\n",
    "\n",
    "    def __init__(self, user_id, item_id, metadata):\n",
    "        self.user_id = torch.tensor(user_id)\n",
    "        self.item_id = torch.tensor(item_id)\n",
    "        self.metadata = torch.tensor(metadata)\n",
    "\n",
    "\n",
    "class DataGenerator(Dataset):\n",
    "\n",
    "    def __init__(self, state_history, reward_history, action_history):\n",
    "        self.state_history = state_history\n",
    "        self.reward_history = reward_history\n",
    "        self.action_history = action_history\n",
    "        self.data = []\n",
    "        self._init_pos_neg()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def _init_pos_neg(self):\n",
    "        for i, r in enumerate(self.reward_history):\n",
    "            if r > 0:\n",
    "                user_id = self.state_history[i][0][0]\n",
    "                action = self.action_history[i]\n",
    "                pos_data = Data(user_id=user_id, item_id=self.state_history[i][action][1],\n",
    "                                metadata=self.state_history[i][action][2:])\n",
    "                for j, state in enumerate(self.state_history[i]):\n",
    "                    item_id = state[1]\n",
    "                    metadata = state[2:]\n",
    "                    data = Data(user_id=user_id, item_id=item_id, metadata=metadata)\n",
    "                    if j != action:\n",
    "                        self.data.append(PosNegData(pos_data, data, 1))\n",
    "\n",
    "    def add_data(self, state, action, reward):\n",
    "        if reward > 0:\n",
    "            user_id = state[0][0]\n",
    "            pos_data = Data(user_id=user_id, item_id=state[action][1], metadata=state[action][2:])\n",
    "            for j, my_state in enumerate(state):\n",
    "                item_id = my_state[1]\n",
    "                metadata = my_state[2:]\n",
    "                data = Data(user_id=user_id, item_id=item_id, metadata=metadata)\n",
    "                if j != action:\n",
    "                    self.data.append(PosNegData(pos_data, data, 1))\n",
    "\n",
    "\n",
    "def collate_data_pos_neg(list_of_data):\n",
    "    raw_data = [data for data in list_of_data]\n",
    "    user_id_pos = torch.stack([data.pos.user_id for data in list_of_data])\n",
    "    item_id_pos = torch.stack([data.pos.item_id for data in list_of_data])\n",
    "    metadata_pos = torch.stack([data.pos.metadata for data in list_of_data])\n",
    "    user_id_neg = torch.stack([data.neg.user_id for data in list_of_data])\n",
    "    item_id_neg = torch.stack([data.neg.item_id for data in list_of_data])\n",
    "    metadata_neg = torch.stack([data.neg.metadata for data in list_of_data])\n",
    "    return {'user_id_pos': user_id_pos, 'item_id_pos': item_id_pos, 'metadata_pos': metadata_pos, 'raw_data': raw_data,\n",
    "            'user_id_neg': user_id_neg, 'item_id_neg': item_id_neg, 'metadata_neg': metadata_neg}\n",
    "\n",
    "\n",
    "def collate_data(list_of_data):\n",
    "    user_id = torch.stack([data.user_id for data in list_of_data])\n",
    "    item_id = torch.stack([data.item_id for data in list_of_data])\n",
    "    metadata = torch.stack([data.metadata for data in list_of_data])\n",
    "    return {'user_id': user_id, 'item_id': item_id, 'metadata': metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interface:\n",
    "\n",
    "    def __init__(self, args):\n",
    "        self.base_url = 'http://{}'.format(args.ip_address_env_2)\n",
    "        self.user_id = args.user_id\n",
    "        self.url_reset = '{}/reset'.format(self.base_url)\n",
    "        self.url_predict = '{}/predict'.format(self.base_url)\n",
    "\n",
    "        r = requests.get(url=self.url_reset, params={'user_id': self.user_id})\n",
    "        data = r.json()\n",
    "        self.state_history = data['state_history']\n",
    "        self.rewards_history = data['rewards_history']\n",
    "        self.action_history = data['action_history']\n",
    "\n",
    "        self.nb_items = data['nb_items']\n",
    "        self.nb_users = data['nb_users']\n",
    "        self.nb_variables = len(self.state_history[0][0]) - 2\n",
    "\n",
    "        self.next_state = data['next_state']\n",
    "\n",
    "    def reset(self):\n",
    "        r = requests.get(url=self.url_reset, params={'user_id': self.user_id})\n",
    "        data = r.json()\n",
    "\n",
    "        self.state_history = data['state_history']\n",
    "        self.rewards_history = data['rewards_history']\n",
    "        self.action_history = data['action_history']\n",
    "\n",
    "        self.nb_items = data['nb_items']\n",
    "        self.nb_users = data['nb_users']\n",
    "\n",
    "        self.next_state = data['next_state']\n",
    "\n",
    "    def predict(self, recommended_item):\n",
    "        r = requests.get(url=self.url_predict, params={'user_id': self.user_id, 'recommended_item': recommended_item})\n",
    "        data = r.json()\n",
    "\n",
    "        self.state_history.append(data['state'])\n",
    "        self.rewards_history.append(data['reward'])\n",
    "        self.action_history.append(recommended_item)\n",
    "\n",
    "        self.next_state = data['state']\n",
    "        return data['state'], data['reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, interface):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        user_embedding_dim = 10\n",
    "        item_embedding_dim = 10\n",
    "        user_meta_dim = 15\n",
    "        item_meta_dim = 15\n",
    "        meta_meta_dim = 30\n",
    "        dense_1_dim = 32\n",
    "        dense_2_dim = 15\n",
    "        out_dim = 1\n",
    "\n",
    "        self.embedding_user = Embedding(num_embeddings=interface.nb_users, embedding_dim=user_embedding_dim)\n",
    "        self.embedding_item = Embedding(num_embeddings=interface.nb_items, embedding_dim=item_embedding_dim)\n",
    "        self.concat_user_meta = Bilinear(in1_features=user_embedding_dim, in2_features=interface.nb_variables, out_features=user_meta_dim)\n",
    "        self.concat_item_meta = Bilinear(in1_features=item_embedding_dim, in2_features=interface.nb_variables, out_features=item_meta_dim)\n",
    "        self.concat_meta_meta = Bilinear(in1_features=user_meta_dim, in2_features=item_meta_dim, out_features=meta_meta_dim)\n",
    "        self.batch_norm_0 = BatchNorm1d(num_features=meta_meta_dim)\n",
    "        self.dropout_0 = Dropout(0.5)\n",
    "        self.dense_1 = Linear(in_features=meta_meta_dim, out_features=dense_1_dim)\n",
    "        self.relu_1 = ReLU()\n",
    "        self.dropout_1 = Dropout(0.5)\n",
    "        self.batch_norm_1 = BatchNorm1d(num_features=dense_1_dim)\n",
    "        self.dense_2 = Linear(in_features=dense_1_dim, out_features=dense_2_dim)\n",
    "        self.relu_2 = ReLU()\n",
    "        self.dropout_2 = Dropout(0.5)\n",
    "        self.batch_norm_2 = BatchNorm1d(num_features=dense_2_dim)\n",
    "        self.dense_3 = Linear(in_features=dense_2_dim, out_features=out_dim)\n",
    "\n",
    "    def forward(self, user_id, item_id, metadata):\n",
    "        user_embedded = self.embedding_user(user_id).squeeze(dim=1)\n",
    "        item_embedded = self.embedding_item(item_id).squeeze(dim=1)\n",
    "        user_and_meta = self.concat_user_meta(user_embedded, metadata)\n",
    "        item_and_meta = self.concat_item_meta(item_embedded, metadata)\n",
    "        meta_and_meta = self.concat_meta_meta(user_and_meta, item_and_meta)\n",
    "        output = self.batch_norm_0(meta_and_meta)\n",
    "        output = self.dropout_0(output)\n",
    "        output = self.dense_1(output)\n",
    "        output = self.relu_1(output)\n",
    "        output = self.batch_norm_1(output)\n",
    "        output = self.dropout_1(output)\n",
    "        output = self.dense_2(output)\n",
    "        output = self.relu_2(output)\n",
    "        output = self.batch_norm_2(output)\n",
    "        output = self.dropout_2(output)\n",
    "        output = self.dense_3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(self, interface, learning_rate=3e-4, validation_split=0.2, batch_size=32, margin=10, min_weight=1,\n",
    "                 num_samples=100):\n",
    "        self.interface = interface\n",
    "        self.network = SiameseNetwork(interface)\n",
    "        self.dataset = DataGenerator(interface.state_history, interface.rewards_history, interface.action_history)\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_split = validation_split\n",
    "        self.min_weight = min_weight\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        self.loss = MarginRankingLoss(margin=margin, reduction='none')\n",
    "\n",
    "        self.optimizer = Adam(self.network.parameters(), lr=learning_rate)\n",
    "        self.lr_scheduler = ReduceLROnPlateau(self.optimizer, factor=0.3, patience=5, threshold=1e-3, verbose=True)\n",
    "\n",
    "    def reset(self):\n",
    "        self.train()\n",
    "        for k in range(100):\n",
    "            self.online()\n",
    "\n",
    "    def train(self):\n",
    "        weights = [data.weight for data in self.dataset]\n",
    "        sampler = WeightedRandomSampler(weights=weights, num_samples=self.num_samples, replacement=True)\n",
    "        data_loader = DataLoader(self.dataset, batch_size=self.batch_size, sampler=sampler,\n",
    "                                 collate_fn=collate_data_pos_neg, drop_last=True)\n",
    "        self.network.train()\n",
    "        cumloss = 0\n",
    "        for inputs in data_loader:\n",
    "            self.optimizer.zero_grad()\n",
    "            output_pos = self.network(inputs['user_id_pos'], inputs['item_id_pos'], inputs['metadata_pos'])\n",
    "            output_neg = self.network(inputs['user_id_neg'], inputs['item_id_neg'], inputs['metadata_neg'])\n",
    "            loss = self.loss(output_pos, output_neg, torch.ones(output_pos.shape))\n",
    "            for j, data in enumerate(inputs['raw_data']):\n",
    "                data.weight = loss[j][0].item()\n",
    "            cumloss += loss.sum().item()\n",
    "            loss = loss.mean()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        print(cumloss / len(self.dataset))\n",
    "\n",
    "    def online(self):\n",
    "        self.network.eval()\n",
    "        l = []\n",
    "        my_state = self.interface.next_state\n",
    "        for m in self.interface.next_state:\n",
    "            data = Data(m[0], m[1], m[2:])\n",
    "            l.append(data)\n",
    "        input = collate_data(l)\n",
    "        output = self.network(input['user_id'], input['item_id'], input['metadata']).squeeze()\n",
    "        recommended_item = output.argmax().item()\n",
    "        state, reward = self.interface.predict(recommended_item)\n",
    "        self.dataset.add_data(my_state, recommended_item, reward)\n",
    "        self.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5735606667524327\n",
      "0.5701457676252852\n",
      "0.5648504106681114\n",
      "0.5628334288041078\n",
      "0.5674541999089002\n",
      "0.561578685459456\n",
      "0.5576747061547752\n",
      "0.5565233434910158\n",
      "0.5573690002476748\n",
      "0.5517563634893421\n",
      "0.5550728661515634\n",
      "0.5582864360444865\n",
      "0.5557974598348382\n",
      "0.5439000838842147\n",
      "0.5497409396701389\n",
      "0.5435412284655449\n",
      "0.5507863797353544\n",
      "0.5486463410901887\n",
      "0.5469788119324253\n",
      "0.5505961100260417\n",
      "0.5473346938434829\n",
      "0.5382688719060923\n",
      "0.5304984704261403\n",
      "0.5393281603073325\n",
      "0.5388333444638103\n",
      "0.5365355795274401\n",
      "0.5412022030407003\n",
      "0.5386790459466088\n",
      "0.5368348194344696\n",
      "0.5404612622453493\n",
      "0.5396469697823973\n",
      "0.5402041550708994\n",
      "0.5308701546232936\n",
      "0.5332542288980626\n",
      "0.521081151972635\n",
      "0.5127983930086694\n",
      "0.5074187460639077\n",
      "0.500336485612182\n",
      "0.49078475397425436\n",
      "0.4908943547387033\n",
      "0.4900552229092662\n",
      "0.4900479568192364\n",
      "0.4910404734653018\n",
      "0.48598662390364716\n",
      "0.48213806614497884\n",
      "0.473140431873834\n",
      "0.47856830957517105\n",
      "0.4807998733140936\n",
      "0.46887802715217325\n",
      "0.46833323075994665\n",
      "0.4685540080012031\n",
      "0.47244644352125736\n",
      "0.4723587672227501\n",
      "0.4684225833550454\n",
      "0.46245534330000604\n",
      "0.46456494105173796\n",
      "0.46394463360944305\n",
      "0.4656606195972365\n",
      "0.4655766297863852\n",
      "0.4645656943898233\n",
      "0.46325535880399926\n",
      "0.46191960175062774\n",
      "0.46755795326491406\n",
      "0.4624233929023853\n",
      "0.45898693044095623\n",
      "0.4632723162965876\n",
      "0.45784247251727406\n",
      "0.458608224717571\n",
      "0.4586824783281474\n",
      "0.45874963448860584\n",
      "0.44990815675899065\n",
      "0.45461285417648445\n",
      "0.452290670698707\n",
      "0.4472130456673495\n",
      "0.4437232166043773\n",
      "0.44195635070380623\n",
      "0.44124995070129647\n",
      "0.4408705047425353\n",
      "0.4399151462871802\n",
      "0.440828250711694\n",
      "0.4399201882000416\n",
      "0.4343605594358582\n",
      "0.43245861495750537\n",
      "0.43235911493716034\n",
      "0.4342689237732818\n",
      "0.4286820850133469\n",
      "0.42353302742998067\n",
      "0.42466635461937774\n",
      "0.42237819646367963\n",
      "0.4249680003319881\n",
      "0.42149811801531456\n",
      "0.42670549472699365\n",
      "0.41997356314933737\n",
      "0.41493065932701373\n",
      "0.4132647415687298\n",
      "0.4145235785122575\n",
      "0.40912158972563084\n",
      "0.40771119151854635\n",
      "0.4071300058186156\n",
      "0.4071624859837495\n",
      "0.41148707895100217\n"
     ]
    }
   ],
   "source": [
    "class Argument:\n",
    "    pass\n",
    "\n",
    "args = Argument\n",
    "args.user_id = 'R3EIFXNYY6XMBXBR01BK'\n",
    "args.ip_address_env_0 = '52.47.62.31'\n",
    "args.ip_address_env_1 = '35.180.254.42'\n",
    "args.ip_address_env_2 = '35.180.178.243'\n",
    "\n",
    "interface = Interface(args)\n",
    "trainer = Trainer(interface)\n",
    "interface.reset()\n",
    "trainer.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
